import {
  __commonJS
} from "./chunk-EWTE5DHJ.js";

// node_modules/opus-recorder/dist/recorder.min.js
var require_recorder_min = __commonJS({
  "node_modules/opus-recorder/dist/recorder.min.js"(exports, module) {
    !(function(e, t) {
      "object" == typeof exports && "object" == typeof module ? module.exports = t() : "function" == typeof define && define.amd ? define([], t) : "object" == typeof exports ? exports.Recorder = t() : e.Recorder = t();
    })("undefined" != typeof self ? self : exports, (function() {
      return (function(e) {
        var t = {};
        function o(n) {
          if (t[n]) return t[n].exports;
          var i = t[n] = { i: n, l: false, exports: {} };
          return e[n].call(i.exports, i, i.exports, o), i.l = true, i.exports;
        }
        return o.m = e, o.c = t, o.d = function(e2, t2, n) {
          o.o(e2, t2) || Object.defineProperty(e2, t2, { enumerable: true, get: n });
        }, o.r = function(e2) {
          "undefined" != typeof Symbol && Symbol.toStringTag && Object.defineProperty(e2, Symbol.toStringTag, { value: "Module" }), Object.defineProperty(e2, "__esModule", { value: true });
        }, o.t = function(e2, t2) {
          if (1 & t2 && (e2 = o(e2)), 8 & t2) return e2;
          if (4 & t2 && "object" == typeof e2 && e2 && e2.__esModule) return e2;
          var n = /* @__PURE__ */ Object.create(null);
          if (o.r(n), Object.defineProperty(n, "default", { enumerable: true, value: e2 }), 2 & t2 && "string" != typeof e2) for (var i in e2) o.d(n, i, (function(t3) {
            return e2[t3];
          }).bind(null, i));
          return n;
        }, o.n = function(e2) {
          var t2 = e2 && e2.__esModule ? function() {
            return e2.default;
          } : function() {
            return e2;
          };
          return o.d(t2, "a", t2), t2;
        }, o.o = function(e2, t2) {
          return Object.prototype.hasOwnProperty.call(e2, t2);
        }, o.p = "", o(o.s = 0);
      })([function(e, t, o) {
        "use strict";
        (function(t2) {
          function o2(e2, t3) {
            if (null == e2) return {};
            var o3, n2, i2 = (function(e3, t4) {
              if (null == e3) return {};
              var o4, n3, i3 = {}, r2 = Object.keys(e3);
              for (n3 = 0; n3 < r2.length; n3++) o4 = r2[n3], t4.indexOf(o4) >= 0 || (i3[o4] = e3[o4]);
              return i3;
            })(e2, t3);
            if (Object.getOwnPropertySymbols) {
              var r = Object.getOwnPropertySymbols(e2);
              for (n2 = 0; n2 < r.length; n2++) o3 = r[n2], t3.indexOf(o3) >= 0 || Object.prototype.propertyIsEnumerable.call(e2, o3) && (i2[o3] = e2[o3]);
            }
            return i2;
          }
          var n = t2.AudioContext || t2.webkitAudioContext, i = function e2() {
            var t3 = this, o3 = arguments.length > 0 && void 0 !== arguments[0] ? arguments[0] : {};
            if (!e2.isRecordingSupported()) throw new Error("Recording is not supported in this browser");
            this.state = "inactive", this.config = Object.assign({ bufferLength: 4096, encoderApplication: 2049, encoderFrameSize: 20, encoderPath: "encoderWorker.min.js", encoderSampleRate: 48e3, maxFramesPerPage: 40, mediaTrackConstraints: true, monitorGain: 0, numberOfChannels: 1, recordingGain: 1, resampleQuality: 3, streamPages: false, wavBitDepth: 16, sourceNode: { context: null } }, o3), this.encodedSamplePosition = 0, this.initAudioContext(), this.initialize = this.initWorklet().then((function() {
              return t3.initEncoder();
            }));
          };
          i.isRecordingSupported = function() {
            var e2 = t2.navigator && t2.navigator.mediaDevices && t2.navigator.mediaDevices.getUserMedia;
            return n && e2 && t2.WebAssembly;
          }, i.version = "8.0.5", i.prototype.clearStream = function() {
            this.stream && (this.stream.getTracks ? this.stream.getTracks().forEach((function(e2) {
              return e2.stop();
            })) : this.stream.stop());
          }, i.prototype.close = function() {
            return this.monitorGainNode.disconnect(), this.recordingGainNode.disconnect(), this.sourceNode && this.sourceNode.disconnect(), this.clearStream(), this.encoder && (this.encoderNode.disconnect(), this.encoder.postMessage({ command: "close" })), this.config.sourceNode.context ? Promise.resolve() : this.audioContext.close();
          }, i.prototype.encodeBuffers = function(e2) {
            if ("recording" === this.state) {
              for (var t3 = [], o3 = 0; o3 < e2.numberOfChannels; o3++) t3[o3] = e2.getChannelData(o3);
              this.encoder.postMessage({ command: "encode", buffers: t3 });
            }
          }, i.prototype.initAudioContext = function() {
            this.audioContext = this.config.sourceNode.context ? this.config.sourceNode.context : new n(), this.monitorGainNode = this.audioContext.createGain(), this.setMonitorGain(this.config.monitorGain), this.recordingGainNode = this.audioContext.createGain(), this.setRecordingGain(this.config.recordingGain);
          }, i.prototype.initEncoder = function() {
            var e2 = this;
            this.audioContext.audioWorklet ? (this.encoderNode = new AudioWorkletNode(this.audioContext, "encoder-worklet", { numberOfOutputs: 0 }), this.encoder = this.encoderNode.port) : (console.log("audioWorklet support not detected. Falling back to scriptProcessor"), this.encodeBuffers = function() {
              return delete e2.encodeBuffers;
            }, this.encoderNode = this.audioContext.createScriptProcessor(this.config.bufferLength, this.config.numberOfChannels, this.config.numberOfChannels), this.encoderNode.onaudioprocess = function(t3) {
              var o3 = t3.inputBuffer;
              return e2.encodeBuffers(o3);
            }, this.encoderNode.connect(this.audioContext.destination), this.encoder = new t2.Worker(this.config.encoderPath));
          }, i.prototype.initSourceNode = function() {
            var e2 = this;
            return this.config.sourceNode.context ? (this.sourceNode = this.config.sourceNode, Promise.resolve()) : t2.navigator.mediaDevices.getUserMedia({ audio: this.config.mediaTrackConstraints }).then((function(t3) {
              e2.stream = t3, e2.sourceNode = e2.audioContext.createMediaStreamSource(t3);
            }));
          }, i.prototype.initWorker = function() {
            var e2 = this, t3 = (this.config.streamPages ? this.streamPage : this.storePage).bind(this);
            return this.recordedPages = [], this.totalLength = 0, new Promise((function(n2) {
              e2.encoder.addEventListener("message", (function o3(i3) {
                var r2 = i3.data;
                switch (r2.message) {
                  case "ready":
                    n2();
                    break;
                  case "page":
                    e2.encodedSamplePosition = r2.samplePosition, t3(r2.page);
                    break;
                  case "done":
                    e2.encoder.removeEventListener("message", o3), e2.finish();
                }
              })), e2.encoder.start && e2.encoder.start();
              var i2 = e2.config, r = (i2.sourceNode, o2(i2, ["sourceNode"]));
              e2.encoder.postMessage(Object.assign({ command: "init", originalSampleRate: e2.audioContext.sampleRate, wavSampleRate: e2.audioContext.sampleRate }, r));
            }));
          }, i.prototype.initWorklet = function() {
            return this.audioContext.audioWorklet ? this.audioContext.audioWorklet.addModule(this.config.encoderPath) : Promise.resolve();
          }, i.prototype.pause = function(e2) {
            var t3 = this;
            if ("recording" === this.state) return this.state = "paused", this.recordingGainNode.disconnect(), e2 && this.config.streamPages ? new Promise((function(e3) {
              t3.encoder.addEventListener("message", (function o3(n2) {
                "flushed" === n2.data.message && (t3.encoder.removeEventListener("message", o3), t3.onpause(), e3());
              })), t3.encoder.start && t3.encoder.start(), t3.encoder.postMessage({ command: "flush" });
            })) : (this.onpause(), Promise.resolve());
          }, i.prototype.resume = function() {
            "paused" === this.state && (this.state = "recording", this.recordingGainNode.connect(this.encoderNode), this.onresume());
          }, i.prototype.setRecordingGain = function(e2) {
            this.config.recordingGain = e2, this.recordingGainNode && this.audioContext && this.recordingGainNode.gain.setTargetAtTime(e2, this.audioContext.currentTime, 0.01);
          }, i.prototype.setMonitorGain = function(e2) {
            this.config.monitorGain = e2, this.monitorGainNode && this.audioContext && this.monitorGainNode.gain.setTargetAtTime(e2, this.audioContext.currentTime, 0.01);
          }, i.prototype.start = function() {
            var e2 = this;
            return "inactive" === this.state ? (this.state = "loading", this.encodedSamplePosition = 0, this.audioContext.resume().then((function() {
              return e2.initialize;
            })).then((function() {
              return Promise.all([e2.initSourceNode(), e2.initWorker()]);
            })).then((function() {
              e2.state = "recording", e2.encoder.postMessage({ command: "getHeaderPages" }), e2.sourceNode.connect(e2.monitorGainNode), e2.sourceNode.connect(e2.recordingGainNode), e2.monitorGainNode.connect(e2.audioContext.destination), e2.recordingGainNode.connect(e2.encoderNode), e2.onstart();
            })).catch((function(t3) {
              throw e2.state = "inactive", t3;
            }))) : Promise.resolve();
          }, i.prototype.stop = function() {
            var e2 = this;
            return "paused" === this.state || "recording" === this.state ? (this.state = "inactive", this.recordingGainNode.connect(this.encoderNode), this.monitorGainNode.disconnect(), this.clearStream(), new Promise((function(t3) {
              e2.encoder.addEventListener("message", (function o3(n2) {
                "done" === n2.data.message && (e2.encoder.removeEventListener("message", o3), t3());
              })), e2.encoder.start && e2.encoder.start(), e2.encoder.postMessage({ command: "done" });
            }))) : Promise.resolve();
          }, i.prototype.storePage = function(e2) {
            this.recordedPages.push(e2), this.totalLength += e2.length;
          }, i.prototype.streamPage = function(e2) {
            this.ondataavailable(e2);
          }, i.prototype.finish = function() {
            if (!this.config.streamPages) {
              var e2 = new Uint8Array(this.totalLength);
              this.recordedPages.reduce((function(t3, o3) {
                return e2.set(o3, t3), t3 + o3.length;
              }), 0), this.ondataavailable(e2);
            }
            this.onstop();
          }, i.prototype.ondataavailable = function() {
          }, i.prototype.onpause = function() {
          }, i.prototype.onresume = function() {
          }, i.prototype.onstart = function() {
          }, i.prototype.onstop = function() {
          }, e.exports = i;
        }).call(this, o(1));
      }, function(e, t) {
        var o;
        o = /* @__PURE__ */ (function() {
          return this;
        })();
        try {
          o = o || new Function("return this")();
        } catch (e2) {
          "object" == typeof window && (o = window);
        }
        e.exports = o;
      }]);
    }));
  }
});
export default require_recorder_min();
//# sourceMappingURL=opus-recorder.js.map
